+++
date = '2025-09-28T20:05:27+08:00'
draft = true
title = '记录迁移学习综述'
+++


#### 迁移学习主要的实现方式
1. 使用预训练模型(Using Pre-trained Models)
2. 使用抽取特征(Feature Extraction)
    这里可能需要与第一点区别，我的理解是这里只提取关键层的特征，比如视觉模型的识别边缘、形状、颜色的能力。
3. 模型微调(Model Fine-tuning)

#### 迁移学习的优势
1. 减少训练时间，同时增强原有模型的效果。
2. 缓解数据缺乏的问题。
3. 更好的泛化性。在这里迁移学习更像是一种学习范式，它可以让GPT或BERT模型的能力提升。

#### 迁移学习技术
根据源数据与目标数据的关系，可以将迁移学习技术分为以下几类：
1. 归纳迁移学习(Inductive Transfer Learning)
    源数据训练的模型与目标数据正相关，这意味着模型只需要继续从目标数据中提取特征即可。
2. 无监督迁移学习(Unsupervised Transfer Learning)
    这常用于目标任务没有可用标记数据的情况。这种方法使模型能够从原任务中学习通用特征，并将这些知识迁移到目标任务中。
3. 传导迁移学习(Transductive Transfer Learning)